\chapter{Advanced Statistical Analysis}

In this course we have presented the basic statistical data analysis with Python. However, Python has much more to offer: a number of Python packages allow you to significantly extend your statistical data analysis and modeling. In the following, I want to give a very brief overview of most interesting and powerful ones that I have found so far:

\begin{itemize}
  \item statsmodels
  \item PyMC
  \item scikit-learn
  \item A.Dobson: "An Introduction to Generalized Linear Models"
\end{itemize}

\section{statsmodels}

\href{http://statsmodels.sourceforge.net/}{Statsmodels} is a Python module that allows users to explore data, estimate statistical models, and perform statistical tests. An extensive list of descriptive statistics, statistical tests, plotting functions, and result statistics are available for different types of data and each estimator. Researchers across fields may find that statsmodels fully meets their needs for statistical computing and data analysis in Python. Features include:

\begin{itemize}
  \item   Linear Regression
  \item   Generalized Linear Models
  \item   Generalized Estimating Equations
  \item   Robust Linear Models
  \item   Linear Mixed Effects Models
  \item   Regression with Discrete Dependent Variables
  \item   ANOVA
  \item   Time Series analysis
  \item   Models for Survival and Duration Analysis
  \item   Statistics (e.g. Multiple Tests, Sample Size Calculations etc.)
  \item   Nonparametric Methods
  \item   Generalized Method of Moments
  \item   Empirical Likelihood
  \item  Graphics functions
  \item  A Datasets Package
\end{itemize}

A first introduction to statistical modeling, as well as some examples, are presented in chapter \nameref{chapter:Models}.

\section{PyMC: Bayesian Statistics and Monte Carlo Markov Modeling}

\href{http://pymc-devs.github.io/pymc/}{PyMC} is a python module that implements Bayesian statistical models and fitting algorithms, including Markov chain Monte Carlo. Its flexibility and extensibility make it applicable to a large suite of problems. Along with core sampling functionality, PyMC includes methods for summarizing output, plotting, goodness-of-fit and convergence diagnostics.

PyMC provides functionalities to make Bayesian analysis as painless as possible. Here is a short list of some of its features:

\begin{itemize}
    \item Fits Bayesian statistical models with Markov chain Monte Carlo and other algorithms.
    \item Includes a large suite of well-documented statistical distributions.
    \item Uses NumPy for numerics wherever possible.
    \item Includes a module for modeling Gaussian processes.
    \item Sampling loops can be paused and tuned manually, or saved and restarted later.
    \item Creates summaries including tables and plots.
    \item Traces can be saved to the disk as plain text, Python pickles, SQLite or MySQL database, or hdf5 archives.
    \item Several convergence diagnostics are available.
    \item Extensible: easily incorporates custom step methods and unusual probability distributions.
    \item MCMC loops can be embedded in larger programs, and results can be analyzed with the full power of Python.
\end{itemize}

A very recommendable, free ebook on Bayesian methods, which also provides a very good introduction to \emph{PyMC}, is \href{http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/}{
Probabilistic Programming \& Bayesian Methods for Hackers}. Warmly recommended!

An introduction to Bayesian Statistics, and an example from the "Bayesian Methods for Hackers" book, are presented in chapter \nameref{chapter:Bayes}.

\section{scikit-learn}

\href{scikit-learn.org}{scikit-learn} is arguably the most advanced open source machine learning package available. It provides simple and efficient tools for data mining and data analysis, covering supervised as well as unsupervised learning.

It provides tools for

\begin{itemize}
  \item \textbf{Classification}    Identifying to which set of categories a new observation belongs to.
  \item \textbf{Regression}    Predicting a continuous value for a new example.
  \item \textbf{Clustering}    Automatic grouping of similar objects into sets.
  \item \textbf{Dimensionality reduction}    Reducing the number of random variables to consider.
  \item \textbf{Model selection}    Comparing, validating and choosing parameters and models.
  \item \textbf{Preprocessing}    Feature extraction and normalization.
\end{itemize}

\section{Generalized Linear Models}

This is not really a Python package, but rather a book. However, this book that Annette Dobson has written has made \emph{Generalized Linear Models (GLM)}\index{general}{Generalized Linear Models, GLM} \cite{Dobson2008} understandable and accessible for me. While the book presents solutions for the models for R and Stata, I have developed Python solutions for almost all examples in the book (\url{https://github.com/thomas-haslwanter/dobson}). 